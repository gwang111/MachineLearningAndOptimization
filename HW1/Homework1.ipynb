{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMO9ssmtZcdFzY+yxbKVbSV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noC_XhIpwfA7",
        "outputId": "cb1a13cd-08d5-4e22-9836-1d553ae65182"
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oocPstBf6Du2"
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "# For Question 2\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For Question 3\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtHo95in71hF"
      },
      "source": [
        "The code block below:\n",
        "\n",
        "1.   Reads in the spam.csv from the most immediate directory. Making sure the coding is for English\n",
        "2.   Next we select all the rows and the first two columns and assign that as the dataframe\n",
        "3.  Next replace all instances of ham in the df as 0 and then replace all instances of spam in the df as 1\n",
        "4.  Next rename the columns v1 to label and v2 to message\n",
        "5.  Finally drop duplicate rows and then reset the indexes accounting for the dropped rows\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8L-3Hgw6ezX"
      },
      "source": [
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "df = df.iloc[:, :2]\n",
        "df = df.replace('ham', 0).replace('spam', 1)\n",
        "df = df.rename(columns = {'v1': 'label', 'v2': 'message'})\n",
        "df = df.drop_duplicates().reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPA2mABw9qx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "411f8910-9da2-47f6-aa3f-64bc23d6227f"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5164</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5165</th>\n",
              "      <td>0</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5166</th>\n",
              "      <td>0</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>0</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5169 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                            message\n",
              "0         0  Go until jurong point, crazy.. Available only ...\n",
              "1         0                      Ok lar... Joking wif u oni...\n",
              "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3         0  U dun say so early hor... U c already then say...\n",
              "4         0  Nah I don't think he goes to usf, he lives aro...\n",
              "...     ...                                                ...\n",
              "5164      1  This is the 2nd time we have tried 2 contact u...\n",
              "5165      0              Will Ì_ b going to esplanade fr home?\n",
              "5166      0  Pity, * was in mood for that. So...any other s...\n",
              "5167      0  The guy did some bitching but I acted like i'd...\n",
              "5168      0                         Rofl. Its true to its name\n",
              "\n",
              "[5169 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsuOsrBEmtST"
      },
      "source": [
        "**Tokenizing data:** Given theses string, the act of tokenizing is to split the inputs up into keywords, elements, etc that are referred to as tokens.\n",
        "\n",
        "**CountVectorizer:** For CountVectorizer, using the default token_pattern input, 2 or more alphanumeric characters in a row are considered a token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWA7pUNxwzEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f38e93-c193-4d53-db38-d5c019515466"
      },
      "source": [
        "messages = df['message']\n",
        "y = df['label']\n",
        "x = CountVectorizer().fit_transform(messages)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2021)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5169x8672 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 68018 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnYt2jZVWfDw"
      },
      "source": [
        "**Unique Tokens Identified**: 4767\n",
        "This was found by summing up all the columns and then counting how many occurances of 1 occurred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGJUOrwVUaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487b2ea0-a9eb-4408-cbee-9435441dcf59"
      },
      "source": [
        "token_occ = x.toarray().sum(axis=0)\n",
        "\n",
        "print(token_occ.shape)\n",
        "\n",
        "unique = 0\n",
        "for i in token_occ:\n",
        "    if i == 1:\n",
        "        unique = unique + 1\n",
        "\n",
        "# unique words\n",
        "print(unique)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8672,)\n",
            "4767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSIFASw3hrYE"
      },
      "source": [
        "Analyzing the training data, the training set does not contain at least one instance of each token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvA8nir3hFmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fff9136-86bd-42c2-d647-bfe4fd7b0122"
      },
      "source": [
        "train_occ = x_train.toarray().sum(axis=0)\n",
        "\n",
        "print(train_occ.shape)\n",
        "\n",
        "atleast_one = True\n",
        "for i in train_occ:\n",
        "    if i == 0: \n",
        "        atleast_one = False        \n",
        "        break\n",
        "\n",
        "print(atleast_one)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8672,)\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiCNyAL1kSco"
      },
      "source": [
        "**Accuracy**: All ML models in sklearn have a score method. This score method takes the model that we've trained using the x and y training data and then when score is called with x and y test passed in, it calculates how accurate the model was in predicting y from x. Accuracy is calculated as:\n",
        "`number of correct predictions / total predictions` (i.e. the percentage of samples that the model was able to successfully predict). This is an important metric because this gives us an immediate idea of how good our machine learning model at doing its job. For example, if the model correctly predicts 90% of the test set, we could potentially say that our model will give us the correct answer 90% of the time. In a way, this metric encompasses both precision and recall.\n",
        "\n",
        "**Precision**: `tp / (tp + fp)` where tp is the number of true positives and fp is the number of false positives. In otherwords, precision is how well the model was able to correctly classify samples as positive. Precision is very important to assessing our model because precision is a great indicator of how consistantly the model is getting \"answers\" right.\n",
        "\n",
        "**Recall**: `tp / (tp + fn)` where tp is the number of true positives and fn is the number of false negatives. Recall is different than precision because recall assesses how well the model is able to find all positive samples. Recall is very important to assessing our model because recall is a great indicator of how well our model is getting all "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhHxkDMCkRyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f29b80c-e1d5-4a32-c6f2-86ad863eab9b"
      },
      "source": [
        "mnb_clf = MultinomialNB()\n",
        "mnb_clf.fit(x_train, y_train)\n",
        "y_hat = mnb_clf.predict(x_test)\n",
        "[mnb_clf.score(x_test, y_test), precision_score(y_test, y_hat), recall_score(y_test, y_hat)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9777562862669246, 0.9154929577464789, 0.9219858156028369]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI9Abf2IBv1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d845b656-1510-4119-93eb-0e2be19bff5d"
      },
      "source": [
        "linear_svc = LinearSVC()\n",
        "linear_svc.fit(x_train, y_train)\n",
        "y_hat = linear_svc.predict(x_test)\n",
        "[linear_svc.score(x_test, y_test), precision_score(y_test, y_hat), recall_score(y_test, y_hat)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9816247582205029, 0.9919354838709677, 0.8723404255319149]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6yc36olBzc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56768b95-0826-45c2-f219-28b5a2610662"
      },
      "source": [
        "logistic_reg = LogisticRegression()\n",
        "logistic_reg.fit(x_train, y_train)\n",
        "y_hat = logistic_reg.predict(x_test)\n",
        "[logistic_reg.score(x_test, y_test), precision_score(y_test, y_hat), recall_score(y_test, y_hat)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9787234042553191, 0.983739837398374, 0.8581560283687943]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ2ujNEXKHfh"
      },
      "source": [
        ""
      ]
    }
  ]
}